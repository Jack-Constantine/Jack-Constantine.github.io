<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>一些名词解释</title>
    <link href="/2023/09/23/%E4%B8%80%E4%BA%9B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"/>
    <url>/2023/09/23/%E4%B8%80%E4%BA%9B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/</url>
    
    <content type="html"><![CDATA[<h1 id="一些名词解释">一些名词解释</h1><p><strong><em>大部分的解释都来自网上</em></strong></p><h2 id="latent-space">Latent Space</h2><p>隐空间/潜在空间</p><p>隐空间是<strong>压缩数据的一个表示</strong>。隐空间的作用是为了找到 <strong>模式</strong>(<code>pattern</code>)而学习数据特征并且简化数据表示。</p><img src="/2023/09/23/%E4%B8%80%E4%BA%9B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/0.jpg" class="" title="一些名词解释"><p>简单来讲呢就是在低维度的空间下，同类型的东西会十分接近。比如下面三个图的两把椅子在潜空间下便十分相似，与桌子将有十分大的差别。</p><img src="/2023/09/23/%E4%B8%80%E4%BA%9B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/1.jpg" class="" title="一些名词解释"><img src="/2023/09/23/%E4%B8%80%E4%BA%9B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/2.jpg" class="" title="一些名词解释"><img src="/2023/09/23/%E4%B8%80%E4%BA%9B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/3.jpg" class="" title="一些名词解释">]]></content>
    
    
    <categories>
      
      <category>名词解释</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像编辑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DragGAN(交互的基于点的图像操作)</title>
    <link href="/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/"/>
    <url>/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="DragGAN-交互的基于点的图像操作"><a href="#DragGAN-交互的基于点的图像操作" class="headerlink" title="DragGAN(交互的基于点的图像操作)"></a>DragGAN(交互的基于点的图像操作)</h1><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p>StyleGAN2</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ol><li>可以进行多点操作</li><li>可以使handle points 准确的接近 target points</li></ol><h2 id="方法-简略版"><a href="#方法-简略版" class="headerlink" title="方法(简略版)"></a>方法(简略版)</h2><ol><li>对handle points 进行监督，使其向target进行移动</li><li>对handle points 进行追踪，使得他们每走一步都已知他们的位置</li></ol><h2 id="方法-详细版"><a href="#方法-详细版" class="headerlink" title="方法(详细版)"></a>方法(详细版)</h2><p>得到一个图像的图 $I$以及他的潜在编码 $w$, 然后进行优化。</p><p>优化分为两步，一个是 <strong>motion supervision</strong> 和 <strong>point tracking</strong> 然后将得到新的图像 $I’$和新的潜在编码 $w’$.</p><ol><li><p><strong>Motion Supervision</strong></p><p>利用生成器中间特征十分具有辨识度的特征进行loss计算。特征图 $F$在StyleGAN2的第6个block后是最好的。</p><p>移动 $p_i$ 到 $t_i$的步骤是通过计算loss.</p><img src="/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/1.jpg" class="" title="DragGAN-交互的基于点的图像操作"><img src="/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/2.jpg" class="" title="DragGAN-交互的基于点的图像操作"></li></ol><p>这个loss用来优化潜在编码 $w$, 且只优化前6层</p><ol><li><p><strong>Point Tracking</strong></p><p>目标是:更新每个handle points $p_i$</p><p>方法是:在一个特征patch上进行Nearest Neighbor search</p></li></ol><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><ol><li><p>$d(Edit Point,Target Point)$ 编辑点与目标点的平均距离</p></li><li><p>$FID$ 反应两组图像的相似度。生成图和真实图特征向量间距离。越小越像</p></li><li><p>时间</p></li><li><p>$MSE$ Mean Square Error 均方误差</p></li><li><p>$LPIPS$ Learned Perceptual Image Patch Similarity 学习感知图像快相似度 衡量两张图的差别 越小越像</p></li><li><p>$MD$ mean distance平均距离</p><img src="/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/3.jpg" class="" title="DragGAN-交互的基于点的图像操作"><img src="/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/4.jpg" class="" title="DragGAN-交互的基于点的图像操作"><img src="/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/5.jpg" class="" title="DragGAN-交互的基于点的图像操作"><img src="/2023/09/21/DragGAN-%E4%BA%A4%E4%BA%92%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/6.jpg" class="" title="DragGAN-交互的基于点的图像操作"></li></ol><p>主要baseline是UserControllableLT</p><h2 id="定量评价"><a href="#定量评价" class="headerlink" title="定量评价"></a>定量评价</h2><p><em>Face landmark manipulation</em></p><p>利用off-the-shelf tool的预测作为ground truth. 然后利用DragGAN进行manipulation然后计算得到图片与ground truth做mean distance(MD).MD可作为评价方法移动的好坏。同时计算了FID. 最大优化步骤为300</p><p><em>Paired image reconstruction</em></p><p>利用和UserControllerableLT同样的设置。利用 $w_1$和 $w_2$生成 $I_1$和 $I_2$。并选取32个像素作为 $U$并与 $I_1$作为输入。来重建 $I2$。最大优化步骤为100</p><p><em>Ablation Study</em></p><p>研究表明StyleGAN第6块后特征图表现最佳。</p><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><ol><li>遮罩对移动有影响</li><li>Manipulation 具有超出分布的可能。防止这种情况可以增加正则化</li><li>局限性 编辑质量受训练集的影响</li></ol>]]></content>
    
    
    <categories>
      
      <category>科研论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像编辑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>欢迎来到我的博客</title>
    <link href="/2023/07/25/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
    <url>/2023/07/25/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="欢迎来到我的博客"><a class="markdownIt-Anchor" href="#欢迎来到我的博客"></a> 欢迎来到我的博客</h1><p>这里是一个某不知名211大学的软件工程的程序猿。</p><p>平时喜欢瞎玩各种乱七八糟的东西。软硬件可能都玩一些。</p><p>我将在这里分享一些我读的科研论文以及一些技术的心得体会。有时候也可以去写一些个人日记。欢迎收藏我的网站</p><p><em><strong>Sky’s not my limit</strong></em></p><img src="/2023/07/25/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/%E6%AC%A2%E8%BF%8E%E9%A1%B5.jpg" class="" title="欢迎来到我的博客">]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
